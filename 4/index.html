<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Neural Radiance Field (NeRF)</title>
  <link rel="stylesheet" href="https://eecs189.org/fa25/assets/css/style.css" />
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      line-height: 1.6;
      color: #222;
      max-width: 900px;
      margin: 40px auto;
      padding: 0 20px;
      background: #fff;
    }

    h1 {
      border-bottom: 2px solid #0066cc;
      padding-bottom: 0.3em;
      color: #004080;
    }

    h2 {
      margin-top: 2.5em;
      font-weight: bold;
      color: #003366;
    }

    p {
      margin-top: 0.5em;
    }

    img {
      max-width: 100%;
      height: auto;
      margin-top: 1em;
      display: block;
    }

    .result-image {
      display: inline-block;
      margin: 15px;
      text-align: center;
    }

    .result-image img {
      width: 250px;
      height: auto;
      border: 1px solid #ccc;
    }

    .image-grid {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
    }

    .image-caption {
      margin-top: 0.5em;
      font-size: 0.9em;
    }
  </style>
</head>
<body>

  <header>
    <h1>Neural Radiance Field (NeRF)</h1>
  </header>

  <main>
    <section>
      <h2>Parts 0.1 & 0.2: Camera Calibration & Capturing a 3D Scan</h2>
      <p>Before building the NeRF, we first print out a sheet of Aruco tags and take ~30 images of it from varying angles and distances while ensuring that the zoom is preserved. This allows us to calibrate our cameras with the help of cv2.calibrateCamera() and gather instrinsic parameters which are later used to estimate our camera pose. Afterwards, we captured a 3D scan of an object by placing it next to a single printed acruo tag and again taking ~30 images from varying angles and distances. I chose my pencil case as my choice of object.</p>
      
      <div class="image-grid">
        <div class="result-image">
          <img src="images/aruco.jpg" style="width:350px;" alt="aruco">
          <div class="image-caption">Acruo Tags for Calibration</div>
        </div>
        
        <div class="result-image">
          <img src="images/aruco-item.jpg" style="width:350px;" alt="acruco-item">
          <div class="image-caption">Aruco Tag with item</div>
        </div>
      </div>  
    </section>

    
    <section>
      <h2>Part 0.3: Estimating Camera Pose</h2>
      <p>Using the camera calibration parameters from part 0.1, we estimate our camera pose by leveraging the rotation matrix and translation vector of our camera's extrinsic matrix along with cv2.solvePnP (and of course, linear algebra). We then pass these into a visualization code to observe the poses in a 3D space. Here are the 3D visualizations of my pencil case scan:</p>
      
      <div class="image-grid">
        <div class="result-image">
          <img src="images/viser-1.png" style="width:400px;" alt="viser-1">
          <div class="image-caption">3D view 1</div>
        </div>
        
        <div class="result-image">
          <img src="images/viser-2.png" style="width:400px;" alt="viser-2">
          <div class="image-caption">3D view 2</div>
        </div>
      </div>
    </section>

    
    <section>
      <h2>Part 0.4: Undistorting Images & Creating a Dataset</h2>
      <p>To wrap up part 0, we remove lens distortions from our images and organize everything into a dataset so that we can use it for NeRF training later on. We also split the data into training, validation, and test sets.</p>
      
    </section>

    
    <section>
      <h2>Part 1: Fitting a Neural Field to a 2D Image</h2>
      <p>To prepare us for 3D NeRF work, we first focus on 2D Neural Fields. Namely, we build a neural network that given an image, attempts to reconstruct it by using pixel coordinates as inputs and outputting some rgb color value. The architecture of my model closely followed the one that is provided in the project specifications (4 Linear layers with ReLU in between, width of 256, learning rate of 1e-2, Adam optimization, MSE loss).</p>

      
      <div class="image-grid">
        <div class="result-image">
          <img src="images/fox.jpg" style="width:400px;" alt="fox">
          <div class="image-caption">Reference Fox Image</div>
        </div>
        

        <div class="result-image">
          <img src="images/fox_grid.jpg" style="width:100%; max-width:1600px; height:auto;" alt="fox_grid">
          <div class="image-caption">Training Progression on Fox Image (L=10, W=256)</div>
        </div>

        <div class="result-image">
          <img src="images/fox_final.jpg" style="width:300px;" alt="fox_final">
          <div class="image-caption">Final Fox Reconstruction (L=10, W=256)</div>
        </div>

        <div class="result-image">
          <img src="images/fox-final-5.jpg" style="width:300px;" alt="fox_final">
          <div class="image-caption">Final Fox Reconstruction (L=5, W=256)</div>
        </div>

        <div class="result-image">
          <img src="images/fox-final-64.jpg" style="width:300px;" alt="fox_final">
          <div class="image-caption">Final Fox Reconstruction (L=10, W=64)</div>
        </div>

        <div class="result-image">
          <img src="images/fox-final-5-64.jpg" style="width:300px;" alt="fox_final">
          <div class="image-caption">Final Fox Reconstruction (L=5, W=64)</div>
        </div>

        <div class="result-image">
          <img src="images/psnr_curve.png" style="width:400px;" alt="psnr">
          <div class="image-caption">PSNR Curve of Fox Image (L=10, W=256)</div>
        </div>
      </div>

      
      <div class="image-grid">
        <div class="result-image">
          <img src="images/pup.jpg" style="width:300px;" alt="pup">
          <div class="image-caption">Reference Puppy Image</div>
        </div>

        <div class="result-image">
          <img src="images/pup-final.jpg" style="width:300px;" alt="pup-final">
          <div class="image-caption">Final Puppy Reconstruction (L=10, W=256)</div>
        </div>

        <div class="result-image">
          <img src="images/pup_grid.jpg" style="width:100%; max-width:1600px; height:auto;" alt="pup_grid">
          <div class="image-caption">Training Progression on Puppy Image (L=10, W=256)</div>
        </div>

        <div class="result-image">
          <img src="images/pup_psnr.png" style="width:400px;" alt="pup-psnr">
          <div class="image-caption">PSNR Curve of Puppy Image (L=10, W=256)</div>
        </div>
      </div>

      
    </section>

    
    <section>
      <h2>Part 2.1: Creating Rays from Cameras</h2>
      <p>After playing with 2D MLPs, we move on to 3D first by implementing a few functions that help us convert between coordinates.</p>
      <p>1. Camera to World Coordinate conversion</p>
      <p>2. Pixel to Camera Coordinate conversion</p>
      <p>3. Pixel to Ray conversion</p>
      <p>In a nutshell, (3) uses (1) and (2) to tranform from pixel to camera, and camera to world to locate ray origin and direction. Afterwards, we develop a few sampling functions to collect samples along rays.</p>
      <p>1. Sampling Rays from Images</p>
      <p>2. Sampling Points along Rays</p>
      <p>______________</p>

      
    </section>

    
  </main>
</body>
</html>
